{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXIbCr7bwtDG"
      },
      "source": [
        "# Early Fusion Transformer Model - CMU-MOSI Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYSzl-AZhYqs",
        "outputId": "44f0ffcf-af7f-4a76-b56d-b7566ba83b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Multimodal-Emotion-Recognition'...\n",
            "remote: Enumerating objects: 570, done.\u001b[K\n",
            "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 570 (delta 41), reused 75 (delta 19), pack-reused 453 (from 2)\u001b[K\n",
            "Receiving objects: 100% (570/570), 327.67 MiB | 20.77 MiB/s, done.\n",
            "Resolving deltas: 100% (257/257), done.\n",
            "Updating files: 100% (85/85), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/M-Jafarkhani/Multimodal-Emotion-Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "mxwY96BulEtC",
        "outputId": "394605cd-1e55-45c2-e371-0c1abf600c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1_XdzdW8UNG1TTS6QcX10uhoS6N11OBit\n",
            "From (redirected): https://drive.google.com/uc?id=1_XdzdW8UNG1TTS6QcX10uhoS6N11OBit&confirm=t&uuid=90a8623c-ece6-40ba-9ab5-1c5285385a34\n",
            "To: /content/mosi_data.pkl\n",
            "100%|██████████| 154M/154M [00:03<00:00, 47.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mosi_data.pkl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "file_id = \"1_XdzdW8UNG1TTS6QcX10uhoS6N11OBit\"\n",
        "destination = \"mosi_data.pkl\"\n",
        "\n",
        "gdown.download(\n",
        "    f\"https://drive.google.com/uc?id={file_id}\", destination, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sC___ekEm3os"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sys.path.append('/content/Multimodal-Emotion-Recognition/src')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YPqzgJJVhmrM"
      },
      "outputs": [],
      "source": [
        "from loader import get_dataloader\n",
        "from unimodals.modules import Transformer, MLP, Sequential, Identity\n",
        "from training.supervised import train, test\n",
        "from fusions.modules import ConcatEarly\n",
        "from utils import get_default_device, save_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fjwNto-UkYsP"
      },
      "outputs": [],
      "source": [
        "FILE_PATH = '/content/mosi_data.pkl'\n",
        "train_data, valid_data, test_data = get_dataloader(FILE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWkeUZ5BDLgj",
        "outputId": "3c10d2f1-919d-463f-df6f-eda79f373aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2PEJEgYllya",
        "outputId": "20fcf972-8348-4eb2-b693-00e9d20f4f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "encoders = [Identity().to(device), Identity().to(device), Identity().to(device)]\n",
        "head = Sequential(Transformer(325, 300).to(device), MLP(300, 128, 1)).to(device)\n",
        "fusion = ConcatEarly().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSnB-YCgnOsC",
        "outputId": "89f06172-2efb-4a73-d375-08416c45c74c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/cudnn/__init__.py:145: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  torch._C._get_cudnn_allow_tf32(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 1.2214\n",
            "Valid Loss: 1.2825\n",
            "Saving Best\n",
            "\n",
            "Epoch [2/100]\n",
            "Train Loss: 1.0019\n",
            "Valid Loss: 1.1743\n",
            "Saving Best\n",
            "\n",
            "Epoch [3/100]\n",
            "Train Loss: 0.9026\n",
            "Valid Loss: 1.0632\n",
            "Saving Best\n",
            "\n",
            "Epoch [4/100]\n",
            "Train Loss: 0.8505\n",
            "Valid Loss: 1.0243\n",
            "Saving Best\n",
            "\n",
            "Epoch [5/100]\n",
            "Train Loss: 0.7959\n",
            "Valid Loss: 1.0589\n",
            "\n",
            "Epoch [6/100]\n",
            "Train Loss: 0.7741\n",
            "Valid Loss: 0.9472\n",
            "Saving Best\n",
            "\n",
            "Epoch [7/100]\n",
            "Train Loss: 0.6960\n",
            "Valid Loss: 0.9301\n",
            "Saving Best\n",
            "\n",
            "Epoch [8/100]\n",
            "Train Loss: 0.6495\n",
            "Valid Loss: 0.9326\n",
            "\n",
            "Epoch [9/100]\n",
            "Train Loss: 0.6108\n",
            "Valid Loss: 0.9623\n",
            "\n",
            "Epoch [10/100]\n",
            "Train Loss: 0.5858\n",
            "Valid Loss: 1.0076\n",
            "\n",
            "Epoch [11/100]\n",
            "Train Loss: 0.5703\n",
            "Valid Loss: 0.9489\n",
            "\n",
            "Epoch [12/100]\n",
            "Train Loss: 0.5199\n",
            "Valid Loss: 0.9527\n",
            "\n",
            "Epoch [13/100]\n",
            "Train Loss: 0.4955\n",
            "Valid Loss: 0.9127\n",
            "Saving Best\n",
            "\n",
            "Epoch [14/100]\n",
            "Train Loss: 0.4622\n",
            "Valid Loss: 0.9289\n",
            "\n",
            "Epoch [15/100]\n",
            "Train Loss: 0.4752\n",
            "Valid Loss: 0.9110\n",
            "Saving Best\n",
            "\n",
            "Epoch [16/100]\n",
            "Train Loss: 0.4349\n",
            "Valid Loss: 0.9283\n",
            "\n",
            "Epoch [17/100]\n",
            "Train Loss: 0.4195\n",
            "Valid Loss: 0.9187\n",
            "\n",
            "Epoch [18/100]\n",
            "Train Loss: 0.4012\n",
            "Valid Loss: 0.9755\n",
            "\n",
            "Epoch [19/100]\n",
            "Train Loss: 0.4183\n",
            "Valid Loss: 0.9439\n",
            "\n",
            "Epoch [20/100]\n",
            "Train Loss: 0.3572\n",
            "Valid Loss: 0.9367\n",
            "\n",
            "Epoch [21/100]\n",
            "Train Loss: 0.3491\n",
            "Valid Loss: 0.9341\n",
            "\n",
            "Epoch [22/100]\n",
            "Train Loss: 0.3237\n",
            "Valid Loss: 1.0095\n",
            "\n",
            "Epoch [23/100]\n",
            "Train Loss: 0.3397\n",
            "Valid Loss: 0.9332\n",
            "Training Time: 37s483ms\n",
            "Training Params: 8103897\n"
          ]
        }
      ],
      "source": [
        "OUTPUT_MODEL_FILE_NAME = \"MOSI_Late_Fusion_Transformer\"\n",
        "\n",
        "train_losses, valid_losses = train(\n",
        "    encoders,\n",
        "    fusion,\n",
        "    head,\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    100,\n",
        "    task=\"regression\",\n",
        "    optimtype=torch.optim.AdamW,\n",
        "    is_packed=True,\n",
        "    early_stop=True,\n",
        "    lr=1e-4,\n",
        "    save=f\"/content/{OUTPUT_MODEL_FILE_NAME}.pt\",\n",
        "    weight_decay=0.01,\n",
        "    objective=torch.nn.L1Loss(),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "dLXyFd9uDfjF",
        "outputId": "02ebcf0b-0e03-4046-b8cb-f7aad2e4ee7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss vs. No. of epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(valid_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.title('Loss vs. No. of epochs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9v8PYdfVD5T5"
      },
      "outputs": [],
      "source": [
        "save_results(train_losses, valid_losses, f'/content/{OUTPUT_MODEL_FILE_NAME}.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-65EkTZD-ss",
        "outputId": "8915feab-2425-4070-d704-dfc0decd9afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 74.8476% | Total Accuracy: 73.6152%\n",
            "Inference Time: 509ms\n",
            "Inference Params: 8103897\n"
          ]
        }
      ],
      "source": [
        "model = torch.load(f\"/content/{OUTPUT_MODEL_FILE_NAME}.pt\", weights_only=False).to(device)\n",
        "\n",
        "test(\n",
        "    model,\n",
        "    test_data,\n",
        "    is_packed=True,\n",
        "    criterion=torch.nn.L1Loss(),\n",
        "    task=\"posneg-classification\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1"
      ],
      "metadata": {
        "id": "uFlCJakfC1pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# SECTION 1: ATCM-FUSION (TEMPORAL PRESERVED)\n",
        "# ============================================\n",
        "\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class TimeAlignedFusionBuffer:\n",
        "    def __init__(self, window_size_ms=200):\n",
        "        self.window_size_ms = window_size_ms\n",
        "\n",
        "    def get_aligned_batch(self, video, audio, text):\n",
        "        B = video.shape[0]\n",
        "        assert audio.shape[0] == B and text.shape[0] == B\n",
        "        T_v, T_a, T_t = video.shape[1], audio.shape[1], text.shape[1]\n",
        "        assert T_v == T_a == T_t, f\"Time mismatch: {T_v}, {T_a}, {T_t}\"\n",
        "        return video, audio, text\n",
        "\n",
        "class LocalAttention(nn.Module):\n",
        "    \"\"\"Temporal fusion without attention\"\"\"\n",
        "    def __init__(self, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.proj_in = nn.Linear(20 + 5 + 300, hidden_dim)\n",
        "        self.proj_out = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, v, a, t):\n",
        "        combined = torch.cat([v, a, t], dim=-1)  # [B, T, 325]\n",
        "        local = self.proj_in(combined)  # [B, T, 128]\n",
        "        local = torch.relu(local)\n",
        "        local = self.proj_out(local)  # [B, T, 128]\n",
        "        return local\n",
        "\n",
        "class GlobalAttention(nn.Module):\n",
        "    \"\"\"GRU for temporal context\"\"\"\n",
        "    def __init__(self, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=hidden_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            dropout=0.0\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output, _ = self.gru(x)  # [B, T, 128]\n",
        "        return output\n",
        "\n",
        "class ATCMFusion(nn.Module):\n",
        "    \"\"\"Preserves temporal: [B, T, D] → [B, T, 128]\"\"\"\n",
        "    def __init__(self, video_dim=20, audio_dim=5, text_dim=300, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.align = TimeAlignedFusionBuffer()\n",
        "\n",
        "        # Project each modality\n",
        "        self.video_proj = nn.Linear(video_dim, hidden_dim)\n",
        "        self.audio_proj = nn.Linear(audio_dim, hidden_dim)\n",
        "        self.text_proj = nn.Linear(text_dim, hidden_dim)\n",
        "\n",
        "        # Local fusion\n",
        "        self.local_fusion = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 3, hidden_dim),  # [B, T, 384] → [B, T, 128]\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        # Global temporal\n",
        "        self.global_attention = GlobalAttention(hidden_dim)\n",
        "\n",
        "        # Final fusion\n",
        "        self.fusion_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, video, audio, text):\n",
        "        # [B, T, 20], [B, T, 5], [B, T, 300]\n",
        "        video, audio, text = self.align.get_aligned_batch(video, audio, text)\n",
        "\n",
        "        # Project modalities\n",
        "        v_proj = self.video_proj(video)  # [B, T, 128]\n",
        "        a_proj = self.audio_proj(audio)  # [B, T, 128]\n",
        "        t_proj = self.text_proj(text)    # [B, T, 128]\n",
        "\n",
        "        # Local fusion\n",
        "        local_cat = torch.cat([v_proj, a_proj, t_proj], dim=-1)  # [B, T, 384]\n",
        "        local_context = self.local_fusion(local_cat)  # [B, T, 128]\n",
        "\n",
        "        # Global temporal\n",
        "        global_context = self.global_attention(local_context)  # [B, T, 128]\n",
        "\n",
        "        # Final fusion\n",
        "        fused = self.fusion_head(global_context)  # [B, T, 128]\n",
        "\n",
        "        return fused  # [B, T, 128] - TEMPORAL PRESERVED!\n",
        "\n"
      ],
      "metadata": {
        "id": "HgAHByJsBO2w"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "(inputs, lengths, inds, labels) = next(iter(train_data))\n",
        "vision_sample, audio_sample, text_sample = inputs[0], inputs[1], inputs[2]\n",
        "\n",
        "Dv, Da, Dt = vision_sample.shape[-1], audio_sample.shape[-1], text_sample.shape[-1]\n",
        "print(f\"Data: Vision={Dv}, Audio={Da}, Text={Dt}, Temporal={vision_sample.shape[1]}\")\n",
        "\n",
        "vision_sample, audio_sample, text_sample = vision_sample.to(device), audio_sample.to(device), text_sample.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "print(f\"Initializing ATCM...\")\n",
        "atcm = ATCMFusion(video_dim=Dv, audio_dim=Da, text_dim=Dt, hidden_dim=128).to(device)\n",
        "print(f\"✓ Parameters: {sum(p.numel() for p in atcm.parameters()):,}\")\n",
        "\n",
        "atcm.eval()\n",
        "with torch.no_grad():\n",
        "    _ = atcm(vision_sample, audio_sample, text_sample)\n",
        "\n",
        "latencies = []\n",
        "with torch.no_grad():\n",
        "    for i in range(10):\n",
        "        if device.type == \"cuda\":\n",
        "            torch.cuda.synchronize()\n",
        "        start = time.time()\n",
        "        fused = atcm(vision_sample, audio_sample, text_sample)\n",
        "        if device.type == \"cuda\":\n",
        "            torch.cuda.synchronize()\n",
        "        latencies.append((time.time() - start) * 1000)\n",
        "\n",
        "avg_latency = np.mean(latencies)\n",
        "print(f\"✓ Latency: {avg_latency:.2f}ms\")\n",
        "print(f\"✓ Output shape: {fused.shape}\")\n",
        "\n",
        "if fused.shape[-1] == 128 and len(fused.shape) == 3:\n",
        "    print(f\"\\n✅ SUCCESS: [B, T, 128] - temporal preserved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-coNzPLBsoG",
        "outputId": "4282ce63-b0a4-4536-b057-ad6ffc9f4ac8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: Vision=20, Audio=5, Text=300, Temporal=34\n",
            "Initializing ATCM...\n",
            "✓ Parameters: 239,872\n",
            "✓ Latency: 0.91ms\n",
            "✓ Output shape: torch.Size([32, 34, 128])\n",
            "\n",
            "✅ SUCCESS: [B, T, 128] - temporal preserved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2"
      ],
      "metadata": {
        "id": "AW8oP01Q4Nc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# SECTION 2: NSAR-EMOTION CLASSIFICATION\n",
        "# ============================================\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "class ContextEmbedding(nn.Module):\n",
        "    \"\"\"Embeds context: domain + speaker\"\"\"\n",
        "    def __init__(self, context_dim=32):\n",
        "        super().__init__()\n",
        "        self.domain_embed = nn.Embedding(5, context_dim)      # 5 domains\n",
        "        self.speaker_embed = nn.Embedding(23, context_dim)    # 23 speakers\n",
        "        self.context_proj = nn.Linear(context_dim * 2, context_dim)\n",
        "\n",
        "    def forward(self, domain_id, speaker_id):\n",
        "        domain_emb = self.domain_embed(domain_id)\n",
        "        speaker_emb = self.speaker_embed(speaker_id)\n",
        "        context = torch.cat([domain_emb, speaker_emb], dim=-1)\n",
        "        return self.context_proj(context)\n",
        "\n",
        "class TemporalAttention(nn.Module):\n",
        "    \"\"\"Learns which timesteps matter most\"\"\"\n",
        "    def __init__(self, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=4, batch_first=True, dropout=0.1)\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        attn_out, attn_weights = self.attention(sequence, sequence, sequence)\n",
        "        return self.norm(sequence + attn_out), attn_weights\n",
        "\n",
        "class NSAR(nn.Module):\n",
        "    \"\"\"Context-Adaptive Emotion Recognition\"\"\"\n",
        "    def __init__(self, hidden_dim=128, context_dim=32, num_emotions=6):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_emotions = num_emotions\n",
        "\n",
        "        self.context_embed = ContextEmbedding(context_dim)\n",
        "        self.temporal_attention = TemporalAttention(hidden_dim)\n",
        "        self.gru = nn.GRU(hidden_dim, hidden_dim, num_layers=2, batch_first=True, dropout=0.2)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim + context_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, num_emotions)\n",
        "        )\n",
        "\n",
        "    def forward(self, fused_sequence, domain_id=None, speaker_id=None):\n",
        "        B, T, D = fused_sequence.shape\n",
        "\n",
        "        # Temporal attention\n",
        "        attn_sequence, attn_weights = self.temporal_attention(fused_sequence)\n",
        "\n",
        "        # GRU processing\n",
        "        gru_out, gru_hidden = self.gru(attn_sequence)\n",
        "        gru_final = gru_hidden[-1]  # [B, 128]\n",
        "\n",
        "        # Context embedding\n",
        "        if domain_id is not None and speaker_id is not None:\n",
        "            context = self.context_embed(domain_id, speaker_id)\n",
        "        else:\n",
        "            context = torch.zeros(B, self.context_embed.context_proj.out_features, device=fused_sequence.device)\n",
        "\n",
        "        # Combine and classify\n",
        "        combined = torch.cat([gru_final, context], dim=-1)\n",
        "        logits = self.classifier(combined)\n",
        "\n",
        "        return logits, attn_weights\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aAWPBGA44Q9U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "print(\"Initializing NSAR...\")\n",
        "nsar = NSAR(hidden_dim=128, context_dim=32, num_emotions=6).to(device)\n",
        "print(f\"✓ NSAR Parameters: {sum(p.numel() for p in nsar.parameters()):,}\")\n",
        "\n",
        "# Test with ATCM output\n",
        "print(f\"\\nTesting NSAR integration...\")\n",
        "print(f\"Input from ATCM: {fused.shape}\")\n",
        "\n",
        "# Without context\n",
        "nsar.eval()\n",
        "with torch.no_grad():\n",
        "    logits_no_context, attn_weights = nsar(fused)\n",
        "print(f\"✓ Output (no context): {logits_no_context.shape}\")\n",
        "\n",
        "# With context (dummy values)\n",
        "domain_ids = torch.randint(0, 5, (32,)).to(device)\n",
        "speaker_ids = torch.randint(0, 23, (32,)).to(device)\n",
        "with torch.no_grad():\n",
        "    logits_with_context, _ = nsar(fused, domain_id=domain_ids, speaker_id=speaker_ids)\n",
        "print(f\"✓ Output (with context): {logits_with_context.shape}\")\n",
        "\n",
        "# Latency\n",
        "latencies = []\n",
        "with torch.no_grad():\n",
        "    for _ in range(10):\n",
        "        if device.type == \"cuda\":\n",
        "            torch.cuda.synchronize()\n",
        "        start = time.time()\n",
        "        logits, _ = nsar(fused, domain_id=domain_ids, speaker_id=speaker_ids)\n",
        "        if device.type == \"cuda\":\n",
        "            torch.cuda.synchronize()\n",
        "        latencies.append((time.time() - start) * 1000)\n",
        "\n",
        "avg_nsar_latency = np.mean(latencies)\n",
        "total_latency = 0.86 + avg_nsar_latency\n",
        "print(f\"\\n✓ NSAR Latency: {avg_nsar_latency:.2f}ms\")\n",
        "print(f\"✓ Total (ATCM + NSAR): {total_latency:.2f}ms\")\n",
        "\n",
        "if total_latency < 200:\n",
        "    print(f\"\\n✅ SUCCESS: {total_latency:.2f}ms << 200ms!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SECTION 2: NSAR COMPLETE ✓\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILY1cA0SC7k7",
        "outputId": "4e2f02c0-8983-4e3a-f4bd-2ee2a02cab1e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing NSAR...\n",
            "✓ NSAR Parameters: 342,310\n",
            "\n",
            "Testing NSAR integration...\n",
            "Input from ATCM: torch.Size([32, 34, 128])\n",
            "✓ Output (no context): torch.Size([32, 6])\n",
            "✓ Output (with context): torch.Size([32, 6])\n",
            "\n",
            "✓ NSAR Latency: 1.97ms\n",
            "✓ Total (ATCM + NSAR): 2.83ms\n",
            "\n",
            "✅ SUCCESS: 2.83ms << 200ms!\n",
            "\n",
            "============================================================\n",
            "SECTION 2: NSAR COMPLETE ✓\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3"
      ],
      "metadata": {
        "id": "ekzWT7oZ4aFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# SECTION 3: GOVERNANCE - DRIFT DETECTION\n",
        "# ============================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import time\n",
        "\n",
        "class DriftDetector:\n",
        "    \"\"\"Detects data distribution shift using Kolmogorov-Smirnov test\"\"\"\n",
        "    def __init__(self, window_size=100, threshold=0.05):\n",
        "        self.window_size = window_size\n",
        "        self.threshold = threshold\n",
        "        self.reference_features = None\n",
        "        self.is_initialized = False\n",
        "\n",
        "    def initialize_reference(self, features):\n",
        "        if features.shape[0] > self.window_size:\n",
        "            self.reference_features = features[-self.window_size:].cpu().numpy()\n",
        "        else:\n",
        "            self.reference_features = features.cpu().numpy()\n",
        "        self.is_initialized = True\n",
        "        print(f\"DriftDetector initialized with {self.reference_features.shape[0]} samples\")\n",
        "\n",
        "    def detect_drift(self, features):\n",
        "        if not self.is_initialized:\n",
        "            return False, 1.0, 0.0\n",
        "\n",
        "        current_features = features.cpu().numpy()\n",
        "        ref_flat = self.reference_features.flatten()\n",
        "        curr_flat = current_features.flatten()\n",
        "\n",
        "        ks_statistic, p_value = stats.ks_2samp(ref_flat, curr_flat)\n",
        "        drift_detected = p_value < self.threshold\n",
        "\n",
        "        return drift_detected, p_value, ks_statistic\n",
        "\n",
        "class ContinualLearner:\n",
        "    \"\"\"Adapts model when drift detected (self-supervised)\"\"\"\n",
        "    def __init__(self, model, learning_rate=0.0001):\n",
        "        self.model = model\n",
        "        self.learning_rate = learning_rate\n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        self.adaptation_steps = 0\n",
        "\n",
        "    def adapt(self, fused_sequence, logits_old, domain_id=None, speaker_id=None):\n",
        "        self.model.train()\n",
        "        logits_new, _ = self.model(fused_sequence, domain_id, speaker_id)\n",
        "\n",
        "        # KL divergence loss: old predictions as pseudo-labels\n",
        "        p_old = torch.softmax(logits_old.detach(), dim=-1)\n",
        "        p_new = torch.log_softmax(logits_new, dim=-1)\n",
        "        kl_loss = torch.nn.functional.kl_div(p_new, p_old, reduction='batchmean')\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        kl_loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.adaptation_steps += 1\n",
        "\n",
        "        return kl_loss.item()\n",
        "\n",
        "class GovernanceSystem:\n",
        "    \"\"\"Unified drift detection + continual learning\"\"\"\n",
        "    def __init__(self, nsar_model, window_size=100, drift_threshold=0.05):\n",
        "        self.drift_detector = DriftDetector(window_size, drift_threshold)\n",
        "        self.continual_learner = ContinualLearner(nsar_model, learning_rate=0.0001)\n",
        "        self.nsar = nsar_model\n",
        "        self.drift_history = []\n",
        "        self.loss_history = []\n",
        "\n",
        "    def process_batch(self, fused_sequence, domain_id, speaker_id):\n",
        "        with torch.no_grad():\n",
        "            logits, _ = self.nsar(fused_sequence, domain_id, speaker_id)\n",
        "\n",
        "        features = fused_sequence.mean(dim=1)  # [B, 128]\n",
        "\n",
        "        if not self.drift_detector.is_initialized:\n",
        "            self.drift_detector.initialize_reference(features)\n",
        "\n",
        "        drift_detected, p_value, ks_statistic = self.drift_detector.detect_drift(features)\n",
        "        self.drift_history.append({\n",
        "            'drift_detected': drift_detected,\n",
        "            'p_value': p_value,\n",
        "            'ks_statistic': ks_statistic\n",
        "        })\n",
        "\n",
        "        if drift_detected:\n",
        "            adaptation_loss = self.continual_learner.adapt(\n",
        "                fused_sequence, logits, domain_id, speaker_id\n",
        "            )\n",
        "            self.loss_history.append(adaptation_loss)\n",
        "\n",
        "        return logits, drift_detected, ks_statistic, p_value\n",
        "\n"
      ],
      "metadata": {
        "id": "eBfnmDwI4chE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "print(\"Initializing Governance System...\")\n",
        "governance = GovernanceSystem(nsar, window_size=50, drift_threshold=0.05)\n",
        "print(\"✓ DriftDetector ready\")\n",
        "print(\"✓ ContinualLearner ready\")\n",
        "\n",
        "# Test on 5 batches\n",
        "print(\"\\nTesting Governance on test batches...\")\n",
        "test_drift_count = 0\n",
        "test_batch_count = 0\n",
        "\n",
        "atcm.eval()\n",
        "nsar.eval()\n",
        "\n",
        "for i, (inputs, lengths, inds, labels) in enumerate(test_data):\n",
        "    if i >= 5:\n",
        "        break\n",
        "\n",
        "    test_batch_count += 1\n",
        "\n",
        "    vision_sample = inputs[0].to(device)\n",
        "    audio_sample = inputs[1].to(device)\n",
        "    text_sample = inputs[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fused = atcm(vision_sample, audio_sample, text_sample)\n",
        "\n",
        "    domain_id = torch.zeros(fused.shape[0], dtype=torch.long).to(device)\n",
        "    speaker_id = torch.zeros(fused.shape[0], dtype=torch.long).to(device)\n",
        "\n",
        "    logits, drift_detected, ks_stat, p_val = governance.process_batch(\n",
        "        fused, domain_id, speaker_id\n",
        "    )\n",
        "\n",
        "    if drift_detected:\n",
        "        test_drift_count += 1\n",
        "\n",
        "    if i == 0:\n",
        "        print(f\"Batch {i+1}: Drift={drift_detected}, KS={ks_stat:.4f}, p={p_val:.4f}\")\n",
        "\n",
        "print(f\"\\nGovernance Statistics:\")\n",
        "print(f\"  Batches: {test_batch_count}\")\n",
        "print(f\"  Drift detected: {test_drift_count}/{test_batch_count}\")\n",
        "print(f\"  Adaptation steps: {governance.continual_learner.adaptation_steps}\")\n",
        "\n",
        "if governance.drift_history:\n",
        "    ks_stats = [d['ks_statistic'] for d in governance.drift_history]\n",
        "    print(f\"  KS Statistic: min={np.min(ks_stats):.4f}, max={np.max(ks_stats):.4f}, mean={np.mean(ks_stats):.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z7FAFcwDtTy",
        "outputId": "6d60888b-edb5-4f99-cb55-846af859fb76"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Governance System...\n",
            "✓ DriftDetector ready\n",
            "✓ ContinualLearner ready\n",
            "\n",
            "Testing Governance on test batches...\n",
            "DriftDetector initialized with 32 samples\n",
            "Batch 1: Drift=False, KS=0.0000, p=1.0000\n",
            "\n",
            "Governance Statistics:\n",
            "  Batches: 5\n",
            "  Drift detected: 0/5\n",
            "  Adaptation steps: 0\n",
            "  KS Statistic: min=0.0000, max=0.0115, mean=0.0081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Latency\n",
        "latencies = []\n",
        "test_batch = next(iter(test_data))\n",
        "inputs, lengths, inds, labels = test_batch\n",
        "vision_sample = inputs[0].to(device)\n",
        "audio_sample = inputs[1].to(device)\n",
        "text_sample = inputs[2].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    fused = atcm(vision_sample, audio_sample, text_sample)\n",
        "\n",
        "domain_id = torch.zeros(fused.shape[0], dtype=torch.long).to(device)\n",
        "speaker_id = torch.zeros(fused.shape[0], dtype=torch.long).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for _ in range(10):\n",
        "        if device.type == \"cuda\":\n",
        "            torch.cuda.synchronize()\n",
        "        start = time.time()\n",
        "        logits, drift_detected, ks_stat, p_val = governance.process_batch(\n",
        "            fused, domain_id, speaker_id\n",
        "        )\n",
        "        if device.type == \"cuda\":\n",
        "            torch.cuda.synchronize()\n",
        "        latencies.append((time.time() - start) * 1000)\n",
        "\n",
        "avg_governance_latency = np.mean(latencies)\n",
        "total_system = 0.86 + 1.32 + avg_governance_latency\n",
        "\n",
        "print(f\"\\n✓ Governance Latency: {avg_governance_latency:.2f}ms\")\n",
        "print(f\"✓ Total System (ATCM + NSAR + Governance): {total_system:.2f}ms\")\n",
        "\n",
        "if total_system < 200:\n",
        "    print(f\"\\n✅ SUCCESS: {total_system:.2f}ms << 200ms!\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SECTION 3: GOVERNANCE COMPLETE ✓\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYv7kjjvD08M",
        "outputId": "b696c27c-7aad-4fbc-f420-6191f815dab3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Governance Latency: 2.44ms\n",
            "✓ Total System (ATCM + NSAR + Governance): 4.62ms\n",
            "\n",
            "✅ SUCCESS: 4.62ms << 200ms!\n",
            "\n",
            "============================================================\n",
            "SECTION 3: GOVERNANCE COMPLETE ✓\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 4: EVALUATION - MODEL COMPARISON"
      ],
      "metadata": {
        "id": "hplwubKIEqpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Trainer:\n",
        "    \"\"\"Trainer for regression (sentiment intensity)\"\"\"\n",
        "    def __init__(self, model, device, lr=1e-4):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "        self.criterion = torch.nn.L1Loss()   # MAE\n",
        "        self.best_loss = float('inf')\n",
        "        self.patience_counter = 0\n",
        "\n",
        "    def train_epoch(self, train_data):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        for inputs, lengths, inds, labels in tqdm(train_data, desc=\"Train\"):\n",
        "            vision = inputs[0].to(self.device)\n",
        "            audio  = inputs[1].to(self.device)\n",
        "            text   = inputs[2].to(self.device)\n",
        "\n",
        "            # ✅ REGRESSION LABELS\n",
        "            labels = labels.to(self.device).float().view(-1, 1)\n",
        "            print(\"Label range:\", labels.min().item(), labels.max().item())\n",
        "\n",
        "            preds = self.model(vision, audio, text)  # [B, 1]\n",
        "            loss = self.criterion(preds, labels)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            batch_count += 1\n",
        "\n",
        "        return total_loss / batch_count\n",
        "\n",
        "    def valid_epoch(self, valid_data):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, lengths, inds, labels in tqdm(valid_data, desc=\"Valid\"):\n",
        "                vision = inputs[0].to(self.device)\n",
        "                audio  = inputs[1].to(self.device)\n",
        "                text   = inputs[2].to(self.device)\n",
        "\n",
        "                labels = labels.to(self.device).float().view(-1, 1)\n",
        "                preds = self.model(vision, audio, text)\n",
        "                loss = self.criterion(preds, labels)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                batch_count += 1\n",
        "\n",
        "        return total_loss / batch_count\n",
        "\n",
        "    def train(self, train_data, valid_data, epochs=50, save_path=None):\n",
        "        train_losses, valid_losses = [], []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            train_loss = self.train_epoch(train_data)\n",
        "            valid_loss = self.valid_epoch(valid_data)\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "            valid_losses.append(valid_loss)\n",
        "\n",
        "            print(f\"Train MAE: {train_loss:.4f}\")\n",
        "            print(f\"Valid MAE: {valid_loss:.4f}\")\n",
        "\n",
        "            if valid_loss < self.best_loss:\n",
        "                self.best_loss = valid_loss\n",
        "                self.patience_counter = 0\n",
        "                if save_path:\n",
        "                    torch.save(self.model.state_dict(), save_path)\n",
        "                    print(f\"✓ Saved best model\")\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "                print(f\"No improvement ({self.patience_counter}/5)\")\n",
        "\n",
        "            if self.patience_counter >= 5:\n",
        "                print(\"✅ Early stopping\")\n",
        "                break\n",
        "\n",
        "        return train_losses, valid_losses\n",
        "\n",
        "\n",
        "class NSARForTraining(torch.nn.Module):\n",
        "    \"\"\"ATCM frozen + NSAR trainable (Regression)\"\"\"\n",
        "    def __init__(self, atcm, nsar):\n",
        "        super().__init__()\n",
        "        self.atcm = atcm\n",
        "        self.nsar = nsar\n",
        "\n",
        "    def forward(self, vision, audio, text):\n",
        "        with torch.no_grad():\n",
        "            fused = self.atcm(vision, audio, text)  # [B, T, 128]\n",
        "\n",
        "        domain_id  = torch.zeros(fused.size(0), dtype=torch.long, device=fused.device)\n",
        "        speaker_id = torch.zeros(fused.size(0), dtype=torch.long, device=fused.device)\n",
        "\n",
        "        preds, _ = self.nsar(fused, domain_id, speaker_id)  # [B, 1]\n",
        "        return preds\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MB26fPvXFwee"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TRAIN NSAR\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING NSAR ON TOP OF ATCM\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "nsar_for_training = NSARForTraining(atcm, nsar).to(device)\n",
        "trainer = Trainer(nsar_for_training, device, lr=1e-4)\n",
        "\n",
        "train_losses, valid_losses = trainer.train(\n",
        "    train_data,\n",
        "    valid_data,\n",
        "    epochs=50,\n",
        "    save_path=\"/content/MOSI_ATCM_NSAR.pt\"\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETE ✓\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Final Train Loss: {train_losses[-1]:.6f}\")\n",
        "print(f\"Final Valid Loss: {valid_losses[-1]:.6f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtNzP00PKg6q",
        "outputId": "3a009b0b-cf3b-4dc4-eb55-50c482f845ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAINING NSAR ON TOP OF ATCM\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Epoch 1/50\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   2%|▏         | 1/41 [00:00<00:06,  6.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.5999999046325684 2.4000000953674316\n",
            "Label range: -3.0 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  12%|█▏        | 5/41 [00:00<00:01, 20.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -3.0 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.4000000953674316\n",
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  22%|██▏       | 9/41 [00:00<00:01, 27.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -1.600000023841858 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  32%|███▏      | 13/41 [00:00<00:00, 30.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.5999999046325684 2.4000000953674316\n",
            "Label range: -2.799999952316284 2.4000000953674316\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  41%|████▏     | 17/41 [00:00<00:00, 32.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -2.5 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  51%|█████     | 21/41 [00:00<00:00, 33.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -1.7999999523162842 2.799999952316284\n",
            "Label range: -2.25 2.799999952316284\n",
            "Label range: -2.200000047683716 3.0\n",
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.5999999046325684 2.200000047683716\n",
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.4000000953674316 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  76%|███████▌  | 31/41 [00:00<00:00, 38.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.5999999046325684 2.200000047683716\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -3.0 2.799999952316284\n",
            "Label range: -2.0 3.0\n",
            "Label range: -2.5999999046325684 2.200000047683716\n",
            "Label range: -2.799999952316284 3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  85%|████████▌ | 35/41 [00:01<00:00, 38.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.0\n",
            "Label range: -2.5999999046325684 2.200000047683716\n",
            "Label range: -2.4000000953674316 2.200000047683716\n",
            "Label range: -1.7999999523162842 -1.399999976158142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 41/41 [00:01<00:00, 33.70it/s]\n",
            "Valid: 100%|██████████| 8/8 [00:00<00:00, 30.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train MAE: 1.3328\n",
            "Valid MAE: 1.4868\n",
            "✓ Saved best model\n",
            "\n",
            "============================================================\n",
            "Epoch 2/50\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/41 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.200000047683716 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  10%|▉         | 4/41 [00:00<00:02, 14.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.799999952316284 2.200000047683716\n",
            "Label range: -1.600000023841858 2.5999999046325684\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.799999952316284\n",
            "Label range: -2.799999952316284 2.200000047683716\n",
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  32%|███▏      | 13/41 [00:00<00:00, 29.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -3.0 2.5999999046325684\n",
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -2.0 2.4000000953674316\n",
            "Label range: -2.0 3.0\n",
            "Label range: -2.799999952316284 2.4000000953674316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  54%|█████▎    | 22/41 [00:00<00:00, 34.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.0 3.0\n",
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -3.0 2.799999952316284\n",
            "Label range: -2.200000047683716 3.0\n",
            "Label range: -2.0 2.4000000953674316\n",
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.200000047683716 2.200000047683716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  85%|████████▌ | 35/41 [00:00<00:00, 47.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -1.7999999523162842 2.799999952316284\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.799999952316284 2.4000000953674316\n",
            "Label range: -3.0 2.4000000953674316\n",
            "Label range: -2.5999999046325684 2.200000047683716\n",
            "Label range: -2.200000047683716 2.4000000953674316\n",
            "Label range: -2.799999952316284 2.200000047683716\n",
            "Label range: -2.799999952316284 3.0\n",
            "Label range: -2.4000000953674316 2.799999952316284\n",
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.200000047683716 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain: 100%|██████████| 41/41 [00:01<00:00, 37.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: 0.0 2.4000000953674316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Valid: 100%|██████████| 8/8 [00:00<00:00, 42.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train MAE: 1.3131\n",
            "Valid MAE: 1.4865\n",
            "✓ Saved best model\n",
            "\n",
            "============================================================\n",
            "Epoch 3/50\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   2%|▏         | 1/41 [00:00<00:04,  9.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.4000000953674316 2.4000000953674316\n",
            "Label range: -2.0 2.200000047683716\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.799999952316284 2.799999952316284\n",
            "Label range: -2.200000047683716 2.4000000953674316\n",
            "Label range: -2.0 3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  17%|█▋        | 7/41 [00:00<00:00, 38.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.200000047683716 3.0\n",
            "Label range: -2.0 2.4000000953674316\n",
            "Label range: -3.0 2.5999999046325684\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.799999952316284\n",
            "Label range: -2.799999952316284 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  32%|███▏      | 13/41 [00:00<00:00, 47.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.4000000953674316 2.799999952316284\n",
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.4000000953674316\n",
            "Label range: -2.4000000953674316 2.799999952316284\n",
            "Label range: -2.0 2.4000000953674316\n",
            "Label range: -1.7999999523162842 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  46%|████▋     | 19/41 [00:00<00:00, 50.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.200000047683716\n",
            "Label range: -2.0 2.200000047683716\n",
            "Label range: -2.0 2.5999999046325684\n",
            "Label range: -2.200000047683716 3.0\n",
            "Label range: -2.799999952316284 2.200000047683716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  63%|██████▎   | 26/41 [00:00<00:00, 54.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.799999952316284 2.799999952316284\n",
            "Label range: -2.200000047683716 2.4000000953674316\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  78%|███████▊  | 32/41 [00:00<00:00, 55.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.0 2.5999999046325684\n",
            "Label range: -2.25 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.200000047683716\n",
            "Label range: -3.0 2.799999952316284\n",
            "Label range: -3.0 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 41/41 [00:00<00:00, 51.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.4000000953674316 3.0\n",
            "Label range: -2.0 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -1.600000023841858 2.5999999046325684\n",
            "Label range: -1.600000023841858 2.4000000953674316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Valid: 100%|██████████| 8/8 [00:00<00:00, 44.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train MAE: 1.3236\n",
            "Valid MAE: 1.4865\n",
            "✓ Saved best model\n",
            "\n",
            "============================================================\n",
            "Epoch 4/50\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   2%|▏         | 1/41 [00:00<00:04,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.799999952316284 3.0\n",
            "Label range: -2.799999952316284 2.799999952316284\n",
            "Label range: -2.5999999046325684 2.0\n",
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -2.200000047683716 2.200000047683716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  17%|█▋        | 7/41 [00:00<00:00, 36.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.0 2.200000047683716\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.0 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  34%|███▍      | 14/41 [00:00<00:00, 48.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -3.0 3.0\n",
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.4000000953674316 3.0\n",
            "Label range: -2.799999952316284 2.799999952316284\n",
            "Label range: -2.4000000953674316 2.799999952316284\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  49%|████▉     | 20/41 [00:00<00:00, 52.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.25 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  63%|██████▎   | 26/41 [00:00<00:00, 54.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.5999999046325684 2.4000000953674316\n",
            "Label range: -3.0 2.200000047683716\n",
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.0 2.200000047683716\n",
            "Label range: -2.0 2.4000000953674316\n",
            "Label range: -2.200000047683716 2.4000000953674316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  78%|███████▊  | 32/41 [00:00<00:00, 56.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.4000000953674316\n",
            "Label range: -2.0 3.0\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.799999952316284 2.200000047683716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 41/41 [00:00<00:00, 51.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -3.0 2.4000000953674316\n",
            "Label range: -0.800000011920929 2.200000047683716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Valid: 100%|██████████| 8/8 [00:00<00:00, 44.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train MAE: 1.3139\n",
            "Valid MAE: 1.4879\n",
            "No improvement (1/5)\n",
            "\n",
            "============================================================\n",
            "Epoch 5/50\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   2%|▏         | 1/41 [00:00<00:04,  9.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.200000047683716 2.200000047683716\n",
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.799999952316284\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -3.0 2.5999999046325684\n",
            "Label range: -1.25 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  17%|█▋        | 7/41 [00:00<00:00, 36.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -2.0 3.0\n",
            "Label range: -2.200000047683716 2.200000047683716\n",
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  34%|███▍      | 14/41 [00:00<00:00, 47.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.0 3.0\n",
            "Label range: -2.200000047683716 3.0\n",
            "Label range: -3.0 2.0\n",
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -2.200000047683716 2.200000047683716\n",
            "Label range: -1.600000023841858 2.799999952316284\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  51%|█████     | 21/41 [00:00<00:00, 52.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.5 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.4000000953674316\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.200000047683716\n",
            "Label range: -2.5999999046325684 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  66%|██████▌   | 27/41 [00:00<00:00, 54.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.4000000953674316\n",
            "Label range: -2.0 3.0\n",
            "Label range: -2.0 2.200000047683716\n",
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.200000047683716 2.4000000953674316\n",
            "Label range: -2.5999999046325684 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  83%|████████▎ | 34/41 [00:00<00:00, 57.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.799999952316284\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain: 100%|██████████| 41/41 [00:00<00:00, 51.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -3.0 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.4000000953674316\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.799999952316284 2.799999952316284\n",
            "Label range: -1.2000000476837158 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Valid: 100%|██████████| 8/8 [00:00<00:00, 43.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train MAE: 1.3241\n",
            "Valid MAE: 1.4879\n",
            "No improvement (2/5)\n",
            "\n",
            "============================================================\n",
            "Epoch 6/50\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   2%|▏         | 1/41 [00:00<00:04,  9.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.4000000953674316 2.799999952316284\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.4000000953674316 3.0\n",
            "Label range: -3.0 2.799999952316284\n",
            "Label range: -1.7999999523162842 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  15%|█▍        | 6/41 [00:00<00:01, 32.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.0 2.4000000953674316\n",
            "Label range: -2.200000047683716 2.200000047683716\n",
            "Label range: -2.4000000953674316 2.799999952316284\n",
            "Label range: -2.799999952316284 2.200000047683716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  44%|████▍     | 18/41 [00:00<00:00, 50.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -2.5999999046325684 2.4000000953674316\n",
            "Label range: -2.5999999046325684 2.200000047683716\n",
            "Label range: -2.25 2.0\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -1.600000023841858 2.4000000953674316\n",
            "Label range: -2.5999999046325684 3.0\n",
            "Label range: -1.7999999523162842 2.200000047683716\n",
            "Label range: -2.799999952316284 2.799999952316284\n",
            "Label range: -2.799999952316284 3.0\n",
            "Label range: -2.799999952316284 2.799999952316284\n",
            "Label range: -2.4000000953674316 3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  76%|███████▌  | 31/41 [00:00<00:00, 56.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.200000047683716 2.4000000953674316\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.5999999046325684 2.4000000953674316\n",
            "Label range: -3.0 2.799999952316284\n",
            "Label range: -2.799999952316284 2.799999952316284\n",
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.0 2.5999999046325684\n",
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -2.200000047683716 2.200000047683716\n",
            "Label range: -3.0 2.799999952316284\n",
            "Label range: -2.200000047683716 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 41/41 [00:00<00:00, 51.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.0 2.4000000953674316\n",
            "Label range: -2.200000047683716 2.4000000953674316\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -1.600000023841858 1.7999999523162842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Valid: 100%|██████████| 8/8 [00:00<00:00, 43.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train MAE: 1.3223\n",
            "Valid MAE: 1.4871\n",
            "No improvement (3/5)\n",
            "\n",
            "============================================================\n",
            "Epoch 7/50\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   5%|▍         | 2/41 [00:00<00:02, 17.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -3.0 2.4000000953674316\n",
            "Label range: -1.7999999523162842 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.4000000953674316\n",
            "Label range: -2.799999952316284 2.799999952316284\n",
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -3.0 2.799999952316284\n",
            "Label range: -2.0 3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  17%|█▋        | 7/41 [00:00<00:00, 35.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.799999952316284\n",
            "Label range: -2.0 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  34%|███▍      | 14/41 [00:00<00:00, 47.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.4000000953674316 2.200000047683716\n",
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -3.0 2.799999952316284\n",
            "Label range: -2.0 2.5999999046325684\n",
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.200000047683716 2.4000000953674316\n",
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  51%|█████     | 21/41 [00:00<00:00, 52.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.0 2.4000000953674316\n",
            "Label range: -2.0 2.4000000953674316\n",
            "Label range: -2.0 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  68%|██████▊   | 28/41 [00:00<00:00, 56.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -1.600000023841858 3.0\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -2.799999952316284 2.200000047683716\n",
            "Label range: -2.5999999046325684 2.0\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.0 2.200000047683716\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  85%|████████▌ | 35/41 [00:00<00:00, 57.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.25 2.200000047683716\n",
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -2.799999952316284 2.4000000953674316\n",
            "Label range: -2.200000047683716 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain: 100%|██████████| 41/41 [00:00<00:00, 52.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.4000000953674316 2.200000047683716\n",
            "Label range: -2.4000000953674316 3.0\n",
            "Label range: -2.0 3.0\n",
            "Label range: -0.800000011920929 2.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Valid: 100%|██████████| 8/8 [00:00<00:00, 42.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train MAE: 1.3172\n",
            "Valid MAE: 1.4870\n",
            "No improvement (4/5)\n",
            "\n",
            "============================================================\n",
            "Epoch 8/50\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:   5%|▍         | 2/41 [00:00<00:02, 17.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -3.0 2.799999952316284\n",
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -2.4000000953674316 2.799999952316284\n",
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -2.0 2.5999999046325684\n",
            "Label range: -1.7999999523162842 2.5999999046325684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  20%|█▉        | 8/41 [00:00<00:00, 40.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -1.7999999523162842 2.5999999046325684\n",
            "Label range: -2.5999999046325684 2.4000000953674316\n",
            "Label range: -2.5999999046325684 2.200000047683716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  34%|███▍      | 14/41 [00:00<00:00, 46.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.0 2.4000000953674316\n",
            "Label range: -2.0 2.5999999046325684\n",
            "Label range: -3.0 2.200000047683716\n",
            "Label range: -2.5999999046325684 2.5999999046325684\n",
            "Label range: -3.0 2.799999952316284\n",
            "Label range: -2.799999952316284 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  49%|████▉     | 20/41 [00:00<00:00, 50.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.0 2.200000047683716\n",
            "Label range: -2.5999999046325684 2.799999952316284\n",
            "Label range: -2.200000047683716 2.200000047683716\n",
            "Label range: -2.799999952316284 2.5999999046325684\n",
            "Label range: -1.7999999523162842 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  63%|██████▎   | 26/41 [00:00<00:00, 53.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.200000047683716 3.0\n",
            "Label range: -2.200000047683716 3.0\n",
            "Label range: -2.799999952316284 2.4000000953674316\n",
            "Label range: -2.0 2.5999999046325684\n",
            "Label range: -2.4000000953674316 3.0\n",
            "Label range: -2.200000047683716 2.5999999046325684\n",
            "Label range: -2.0 2.799999952316284\n",
            "Label range: -2.799999952316284 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:  80%|████████  | 33/41 [00:00<00:00, 56.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.4000000953674316 2.4000000953674316\n",
            "Label range: -2.200000047683716 2.799999952316284\n",
            "Label range: -2.0 2.5999999046325684\n",
            "Label range: -2.200000047683716 2.200000047683716\n",
            "Label range: -2.5999999046325684 2.799999952316284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 41/41 [00:00<00:00, 51.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label range: -2.0 2.4000000953674316\n",
            "Label range: -2.4000000953674316 2.5999999046325684\n",
            "Label range: -2.799999952316284 2.200000047683716\n",
            "Label range: -2.0 3.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Valid: 100%|██████████| 8/8 [00:00<00:00, 44.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train MAE: 1.3326\n",
            "Valid MAE: 1.4872\n",
            "No improvement (5/5)\n",
            "✅ Early stopping\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETE ✓\n",
            "============================================================\n",
            "Final Train Loss: 1.332551\n",
            "Final Valid Loss: 1.487162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# SAVE MODELS\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAVING MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "torch.save(atcm.state_dict(), \"/content/MOSI_ATCM.pt\")\n",
        "print(\"✓ Saved: MOSI_ATCM.pt\")\n",
        "\n",
        "torch.save(nsar.state_dict(), \"/content/MOSI_NSAR.pt\")\n",
        "print(\"✓ Saved: MOSI_NSAR.pt\")\n",
        "\n",
        "torch.save(nsar_for_training.state_dict(), \"/content/MOSI_ATCM_NSAR_wrapped.pt\")\n",
        "print(\"✓ Saved: MOSI_ATCM_NSAR_wrapped.pt\")\n",
        "\n",
        "# Save history\n",
        "import json\n",
        "history = {\n",
        "    'train_losses': train_losses,\n",
        "    'valid_losses': valid_losses,\n",
        "    'best_valid_loss': min(valid_losses),\n",
        "    'epochs': len(train_losses)\n",
        "}\n",
        "with open('/content/training_history.json', 'w') as f:\n",
        "    json.dump(history, f, indent=2)\n",
        "print(\"✓ Saved: training_history.json\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING SECTION COMPLETE ✓\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG-gGVWGKpzk",
        "outputId": "5af61566-a6d5-49bf-e2eb-96e361704c4e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "SAVING MODELS\n",
            "============================================================\n",
            "✓ Saved: MOSI_ATCM.pt\n",
            "✓ Saved: MOSI_NSAR.pt\n",
            "✓ Saved: MOSI_ATCM_NSAR_wrapped.pt\n",
            "✓ Saved: training_history.json\n",
            "\n",
            "============================================================\n",
            "TRAINING SECTION COMPLETE ✓\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model comparison"
      ],
      "metadata": {
        "id": "dC3YIblwRI4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vision, audio, text = next(iter(valid_loader))[0]\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = baseline_wrapped(\n",
        "        vision.to(device),\n",
        "        audio.to(device),\n",
        "        text.to(device)\n",
        "    )\n",
        "\n",
        "print(out.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "sq55h4InU25u",
        "outputId": "40536874-f777-4b85-c530-b5c59bbd8a4f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'valid_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1424921514.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     out = baseline_wrapped(\n\u001b[1;32m      5\u001b[0m         \u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'valid_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# SECTION 4: EVALUATION (REGRESSION - MOSI) FIXED\n",
        "# ============================================\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# ============================================\n",
        "# FIXED BASELINE WRAPPER FOR MMDL\n",
        "# ============================================\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BaselineWrapper(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Correct wrapper for MMDL-style fusion baselines\n",
        "    Expects a LIST of modality tensors: [v, a, t]\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        baseline_model,\n",
        "        d_vision,\n",
        "        d_audio,\n",
        "        d_text,\n",
        "        d_model=128,\n",
        "        max_seq_len=50\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.baseline = baseline_model\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        self.v_proj = torch.nn.Linear(d_vision, d_model)\n",
        "        self.a_proj = torch.nn.Linear(d_audio,  d_model)\n",
        "        self.t_proj = torch.nn.Linear(d_text,   d_model)\n",
        "\n",
        "    def pad_time(self, x):\n",
        "        T = x.size(1)\n",
        "        if T < self.max_seq_len:\n",
        "            x = F.pad(x, (0, 0, 0, self.max_seq_len - T))\n",
        "        return x[:, :self.max_seq_len]\n",
        "\n",
        "    def forward(self, vision, audio, text):\n",
        "        vision = self.pad_time(vision)\n",
        "        audio  = self.pad_time(audio)\n",
        "        text   = self.pad_time(text)\n",
        "\n",
        "        v = self.v_proj(vision)\n",
        "        a = self.a_proj(audio)\n",
        "        t = self.t_proj(text)\n",
        "\n",
        "        dummy = torch.zeros_like(v)\n",
        "\n",
        "        preds = self.baseline([v, a, t, dummy])\n",
        "        return preds.view(-1, 1)\n",
        "\n",
        "\n",
        "\n",
        "baseline_wrapped = BaselineWrapper(\n",
        "    baseline_model=model,\n",
        "    d_vision=vision.size(-1),\n",
        "    d_audio=audio.size(-1),\n",
        "    d_text=text.size(-1),\n",
        "    d_model=128,\n",
        "    max_seq_len=50\n",
        ").to(device)\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_regression_model(model_name, model, atcm, data_loader, device, use_governance=False, governance_system=None, max_batches=None):\n",
        "    model.eval()\n",
        "    if atcm is not None: atcm.eval()\n",
        "\n",
        "    all_preds, all_labels = [], []\n",
        "    mae_losses, mse_losses = [], []\n",
        "\n",
        "    l1 = torch.nn.L1Loss(reduction=\"none\")\n",
        "    l2 = torch.nn.MSELoss(reduction=\"none\")\n",
        "\n",
        "    batch_count = 0\n",
        "    for batch in tqdm(data_loader, desc=f\"Eval {model_name}\"):\n",
        "        if max_batches is not None and batch_count >= max_batches:\n",
        "            break\n",
        "        batch_count += 1\n",
        "\n",
        "        inputs, lengths, inds, labels = batch\n",
        "        vision = inputs[0].to(device)\n",
        "        audio = inputs[1].to(device)\n",
        "        text = inputs[2].to(device)\n",
        "        labels = labels.to(device).float().view(-1, 1)  # [B, 1]\n",
        "\n",
        "        # Forward pass\n",
        "        if atcm is not None:\n",
        "            fused = atcm(vision, audio, text)  # [B, T, 128]\n",
        "            domain_id = torch.zeros(fused.size(0), dtype=torch.long, device=device)\n",
        "            speaker_id = torch.zeros(fused.size(0), dtype=torch.long, device=device)\n",
        "\n",
        "            if use_governance and governance_system is not None:\n",
        "                preds, _, _, _ = governance_system.process_batch(fused, domain_id, speaker_id)\n",
        "            else:\n",
        "                preds, _ = model(fused, domain_id, speaker_id)  # [B, 1]\n",
        "        else:\n",
        "            # Baseline (packed format)\n",
        "            preds = model(vision, audio, text)  # [B, 1]\n",
        "\n",
        "        preds = preds.view(-1, 1)\n",
        "        all_preds.append(preds.detach().cpu().numpy())\n",
        "        all_labels.append(labels.detach().cpu().numpy())\n",
        "\n",
        "        mae_losses.append(l1(preds, labels).mean().item())\n",
        "        mse_losses.append(l2(preds, labels).mean().item())\n",
        "\n",
        "    all_preds = np.concatenate(all_preds).reshape(-1)\n",
        "    all_labels = np.concatenate(all_labels).reshape(-1)\n",
        "\n",
        "    mae = np.mean(np.abs(all_preds - all_labels))\n",
        "    mse = np.mean((all_preds - all_labels) ** 2)\n",
        "\n",
        "    pearson_r, pearson_p = pearsonr(all_preds, all_labels)\n",
        "    spearman_r, spearman_p = spearmanr(all_preds, all_labels)\n",
        "\n",
        "    return {\n",
        "        \"model\": model_name,\n",
        "        \"num_samples\": int(len(all_labels)),\n",
        "        \"mae\": float(mae),\n",
        "        \"mse\": float(mse),\n",
        "        \"pearson_r\": float(pearson_r),\n",
        "        \"pearson_p\": float(pearson_p),\n",
        "        \"spearman_r\": float(spearman_r),\n",
        "        \"spearman_p\": float(spearman_p),\n",
        "    }, all_preds, all_labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FWCVm4KkEsQl"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with torch.no_grad():\n",
        "    out = baseline_wrapped(vision.to(device), audio.to(device), text.to(device))\n",
        "\n",
        "print(out.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "FIfLSt46V_D6",
        "outputId": "97d05b67-e361-409f-e582-17f1396c9bde"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 3 is out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4084239972.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4212120382.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, vision, audio, text)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Multimodal-Emotion-Recognition/src/training/supervised.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_padding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_abs_string_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m_get_abs_string_index\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"index {idx} is out of range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 3 is out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== RUN EVALUATION =====\n",
        "print(\"=\" * 60)\n",
        "print(\"SECTION 4: REGRESSION EVALUATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "all_results = []\n",
        "\n",
        "# 1. Baseline\n",
        "print(\"\\n[1/3] Baseline...\")\n",
        "# Use in evaluation:\n",
        "baseline_metrics, baseline_preds, baseline_labels = evaluate_regression_model(\n",
        "    \"Baseline (Late Fusion Transformer)\",\n",
        "    baseline_wrapped,  # ← Use this!\n",
        "    atcm=None,\n",
        "    data_loader=test_data,\n",
        "    device=device,\n",
        "    max_batches=20,\n",
        ")\n",
        "print(f\"✓ MAE: {baseline_metrics['mae']:.4f} | Pearson: {baseline_metrics['pearson_r']:.4f}\")\n",
        "all_results.append(baseline_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "ATgwHGuxReA8",
        "outputId": "29c5a3bb-5332-45a2-ed2c-f7a9b9a3f46d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "SECTION 4: REGRESSION EVALUATION\n",
            "============================================================\n",
            "\n",
            "[1/3] Baseline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval Baseline (Late Fusion Transformer):   0%|          | 0/22 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 3 is out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2745438765.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[1/3] Baseline...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Use in evaluation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m baseline_metrics, baseline_preds, baseline_labels = evaluate_regression_model(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"Baseline (Late Fusion Transformer)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbaseline_wrapped\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# ← Use this!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4212120382.py\u001b[0m in \u001b[0;36mevaluate_regression_model\u001b[0;34m(model_name, model, atcm, data_loader, device, use_governance, governance_system, max_batches)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;31m# Baseline (packed format)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4212120382.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, vision, audio, text)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Multimodal-Emotion-Recognition/src/training/supervised.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_padding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_abs_string_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m_get_abs_string_index\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"index {idx} is out of range\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 3 is out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ATCM + NSAR\n",
        "print(\"\\n[2/3] ATCM + NSAR...\")\n",
        "atcm_nsar_metrics, atcm_nsar_preds, atcm_nsar_labels = evaluate_regression_model(\n",
        "    \"ATCM + NSAR\",\n",
        "    nsar,\n",
        "    atcm=atcm,\n",
        "    data_loader=test_data,\n",
        "    device=device,\n",
        "    max_batches=20,\n",
        ")\n",
        "print(f\"✓ MAE: {atcm_nsar_metrics['mae']:.4f} | Pearson: {atcm_nsar_metrics['pearson_r']:.4f}\")\n",
        "all_results.append(atcm_nsar_metrics)"
      ],
      "metadata": {
        "id": "Rm-zpvbdRbAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. ATCM + NSAR + Governance\n",
        "print(\"\\n[3/3] Full System...\")\n",
        "full_metrics, full_preds, full_labels = evaluate_regression_model(\n",
        "    \"ATCM + NSAR + Governance\",\n",
        "    nsar,\n",
        "    atcm=atcm,\n",
        "    data_loader=test_data,\n",
        "    device=device,\n",
        "    use_governance=True,\n",
        "    governance_system=governance,\n",
        "    max_batches=20,\n",
        ")\n",
        "print(f\"✓ MAE: {full_metrics['mae']:.4f} | Pearson: {full_metrics['pearson_r']:.4f}\")\n",
        "all_results.append(full_metrics)"
      ],
      "metadata": {
        "id": "RNgc__OfRUty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== SAVE RESULTS =====\n",
        "results_df = pd.DataFrame(all_results)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "results_df.to_csv(\"evaluation_results_regression.csv\", index=False)\n",
        "print(\"\\n✓ Saved: evaluation_results_regression.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SECTION 4 COMPLETE ✓\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "m6XfiE3wRP7s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}